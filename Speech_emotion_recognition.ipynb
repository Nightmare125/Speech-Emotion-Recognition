{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nightmare125/Speech-Emotion-Recognition/blob/main/Speech_emotion_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq0Km-vIdQTD",
        "outputId": "d5e2850f-1fb4-4cf8-d478-4c793bf608da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Libraries\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O(e.g. pd.rad_csv)\n",
        "import os #to use operating system dependent functionality\n",
        "import librosa # To extract speech features\n",
        "import wave # read and write WAV files\n",
        "import matplotlib.pyplot as plt # to generate the visualisation\n",
        "\n",
        "\n",
        "#MLP Classifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#LSTM Classifier\n",
        "import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "print(\"Loaded Libraries\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "926rK-Jlk3TL",
        "outputId": "4bbdfb9b-cb5d-4c8a-b943-994fadf1bccf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_mfcc(wav_file_name):\n",
        "# This function extracts mfcc features and obtains the mean of each dimension\n",
        "# Input : path_to_wav_file\n",
        "# Output : mfcc_features '''\n",
        " y, sr = librosa.load(wav_file_name)\n",
        " mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T,axis=0)\n",
        " return mfccs"
      ],
      "metadata": {
        "id": "gRvki1rVmLf6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Dataset\n"
      ],
      "metadata": {
        "id": "6NjPzo52pHOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speech_labels = [] #to save extracted labels/file\n",
        "speech_data =[] #to save extracted features\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/ravdess'):\n",
        "  for filename in filenames:\n",
        "    #print(os.path.join(dirname, filename))\n",
        "    speech_labels.append(int(filename[7:8]) - 1)#the index 7 and 8 of the file name represent the emotion label\n",
        "    wav_file_name = os.path.join(dirname, filename)\n",
        "    speech_data.append(extract_mfcc(wav_file_name))\n",
        "print(\"Dataset Loaded\")\n"
      ],
      "metadata": {
        "id": "2VR6veSKp8Wf",
        "outputId": "da5aefb7-39c8-4279-b5d8-198ab86c66af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "speech_data"
      ],
      "metadata": {
        "id": "UZH3o2M-8Ei9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert label and data to arrays\n",
        "speech_data_array = np.asarray(speech_data)#convert input into an array\n",
        "speech_label_array = np.array(speech_labels)\n",
        "speech_label_array.shape #get tuple of array dimensions\n",
        "\n",
        "# make categorical labels\n",
        "labels_categorical = to_categorical(speech_label_array) #converts a class vector to binary matrix\n",
        "labels_categorical.shape"
      ],
      "metadata": {
        "id": "F1JKPZ038hrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speech_data_array.shape"
      ],
      "metadata": {
        "id": "K4Olu5vr-Vd1",
        "outputId": "565a4b9a-0f22-458a-e598-675d69fbce6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1455, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(np.array(speech_data_array),labels_categorical, test_size=0.20, random_state=9)"
      ],
      "metadata": {
        "id": "nXaCh_Kd-uGl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import training\n",
        "#Split the training, validating and testing sets\n",
        "number_of_samples = speech_data_array.shape[0]\n",
        "training_samples = int(number_of_samples * 0.8)\n",
        "validation_samples = int(number_of_samples * 0.1)\n",
        "test_samples = int(number_of_samples *0.1)\n"
      ],
      "metadata": {
        "id": "TLqhwkE3_kYl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the LSTM Model\n",
        "def create_model_LSTM():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(128, return_sequences=False, input_shape=(40,1)))\n",
        "  model.add(Dense(64))\n",
        "  model.add((Dropout(0.4)))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dense(32))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dense(8))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "  \n",
        "  #configures the model for training\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        " \n",
        " "
      ],
      "metadata": {
        "id": "i3SaRs7J4Rri"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.expand_dims(speech_data_array[:training_samples], -1)"
      ],
      "metadata": {
        "id": "C_vPx7XB_j9R"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w.shape"
      ],
      "metadata": {
        "id": "v_N7gge-AApV",
        "outputId": "0872a9ab-b757-4e44-8d5b-cda739e1d2d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1164, 40, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train using LSTM model\n",
        "model_A = create_model_LSTM()\n",
        "history = model_A.fit(np.expand_dims(speech_data_array[:training_samples], -1), labels_categorical[:training_samples], validation_data=(np.expand_dims(speech_data_array[training_samples:training_samples+validation_samples], -1), labels_categorical[training_samples:training_samples+validation_samples]), epochs = 200, shuffle = True)"
      ],
      "metadata": {
        "id": "ehwx0JdYCwBq",
        "outputId": "12711169-ac78-4a82-b0c7-30eca79694cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "37/37 [==============================] - 6s 80ms/step - loss: 2.0769 - accuracy: 0.1400 - val_loss: 2.0518 - val_accuracy: 0.1586\n",
            "Epoch 2/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 2.0540 - accuracy: 0.1615 - val_loss: 2.0424 - val_accuracy: 0.2138\n",
            "Epoch 3/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 2.0433 - accuracy: 0.1615 - val_loss: 2.0262 - val_accuracy: 0.2276\n",
            "Epoch 4/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 2.0229 - accuracy: 0.1993 - val_loss: 1.9711 - val_accuracy: 0.3862\n",
            "Epoch 5/200\n",
            "37/37 [==============================] - 2s 60ms/step - loss: 1.9803 - accuracy: 0.2311 - val_loss: 1.9496 - val_accuracy: 0.2552\n",
            "Epoch 6/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.9527 - accuracy: 0.2440 - val_loss: 1.9488 - val_accuracy: 0.2552\n",
            "Epoch 7/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.9586 - accuracy: 0.2208 - val_loss: 1.8980 - val_accuracy: 0.3241\n",
            "Epoch 8/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.9211 - accuracy: 0.2543 - val_loss: 1.8685 - val_accuracy: 0.3379\n",
            "Epoch 9/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.8840 - accuracy: 0.2586 - val_loss: 1.8529 - val_accuracy: 0.3034\n",
            "Epoch 10/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.8794 - accuracy: 0.2861 - val_loss: 1.7942 - val_accuracy: 0.3448\n",
            "Epoch 11/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.8641 - accuracy: 0.2835 - val_loss: 1.8527 - val_accuracy: 0.2483\n",
            "Epoch 12/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.8505 - accuracy: 0.2904 - val_loss: 1.8973 - val_accuracy: 0.2138\n",
            "Epoch 13/200\n",
            "37/37 [==============================] - 2s 60ms/step - loss: 1.8544 - accuracy: 0.2990 - val_loss: 1.8330 - val_accuracy: 0.2966\n",
            "Epoch 14/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.8348 - accuracy: 0.3050 - val_loss: 1.8532 - val_accuracy: 0.3034\n",
            "Epoch 15/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.8262 - accuracy: 0.2973 - val_loss: 1.7845 - val_accuracy: 0.3655\n",
            "Epoch 16/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.8113 - accuracy: 0.2981 - val_loss: 1.8729 - val_accuracy: 0.2828\n",
            "Epoch 17/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.8096 - accuracy: 0.3093 - val_loss: 1.8157 - val_accuracy: 0.3034\n",
            "Epoch 18/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.7987 - accuracy: 0.3213 - val_loss: 1.8362 - val_accuracy: 0.2759\n",
            "Epoch 19/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.8148 - accuracy: 0.2887 - val_loss: 1.8613 - val_accuracy: 0.3172\n",
            "Epoch 20/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.7855 - accuracy: 0.3033 - val_loss: 1.8688 - val_accuracy: 0.2966\n",
            "Epoch 21/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.7783 - accuracy: 0.3162 - val_loss: 1.8440 - val_accuracy: 0.3172\n",
            "Epoch 22/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.7449 - accuracy: 0.3290 - val_loss: 1.8410 - val_accuracy: 0.3172\n",
            "Epoch 23/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.7552 - accuracy: 0.3179 - val_loss: 1.9104 - val_accuracy: 0.2897\n",
            "Epoch 24/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.7531 - accuracy: 0.3230 - val_loss: 1.9642 - val_accuracy: 0.1793\n",
            "Epoch 25/200\n",
            "37/37 [==============================] - 2s 60ms/step - loss: 1.7510 - accuracy: 0.3376 - val_loss: 1.9105 - val_accuracy: 0.2759\n",
            "Epoch 26/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.7186 - accuracy: 0.3273 - val_loss: 1.9200 - val_accuracy: 0.2690\n",
            "Epoch 27/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.7284 - accuracy: 0.3445 - val_loss: 1.8569 - val_accuracy: 0.2897\n",
            "Epoch 28/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 1.7142 - accuracy: 0.3342 - val_loss: 1.8584 - val_accuracy: 0.2828\n",
            "Epoch 29/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 1.7271 - accuracy: 0.3359 - val_loss: 1.8555 - val_accuracy: 0.2897\n",
            "Epoch 30/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.6654 - accuracy: 0.3634 - val_loss: 1.9049 - val_accuracy: 0.3034\n",
            "Epoch 31/200\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 1.6665 - accuracy: 0.3625 - val_loss: 1.9039 - val_accuracy: 0.2621\n",
            "Epoch 32/200\n",
            "37/37 [==============================] - 4s 115ms/step - loss: 1.6611 - accuracy: 0.3608 - val_loss: 1.9015 - val_accuracy: 0.2552\n",
            "Epoch 33/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.6838 - accuracy: 0.3505 - val_loss: 1.8028 - val_accuracy: 0.3034\n",
            "Epoch 34/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.6849 - accuracy: 0.3660 - val_loss: 1.9061 - val_accuracy: 0.2345\n",
            "Epoch 35/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.6640 - accuracy: 0.3540 - val_loss: 1.8775 - val_accuracy: 0.2345\n",
            "Epoch 36/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.6357 - accuracy: 0.3634 - val_loss: 1.9033 - val_accuracy: 0.2621\n",
            "Epoch 37/200\n",
            "37/37 [==============================] - 2s 60ms/step - loss: 1.6308 - accuracy: 0.3600 - val_loss: 1.8968 - val_accuracy: 0.2690\n",
            "Epoch 38/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.6446 - accuracy: 0.3582 - val_loss: 1.8921 - val_accuracy: 0.3103\n",
            "Epoch 39/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.6200 - accuracy: 0.3900 - val_loss: 1.8765 - val_accuracy: 0.2828\n",
            "Epoch 40/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.5885 - accuracy: 0.4012 - val_loss: 1.8621 - val_accuracy: 0.3241\n",
            "Epoch 41/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.5935 - accuracy: 0.3960 - val_loss: 1.8971 - val_accuracy: 0.2483\n",
            "Epoch 42/200\n",
            "37/37 [==============================] - 3s 85ms/step - loss: 1.6099 - accuracy: 0.3754 - val_loss: 1.9473 - val_accuracy: 0.3310\n",
            "Epoch 43/200\n",
            "37/37 [==============================] - 4s 96ms/step - loss: 1.6054 - accuracy: 0.3711 - val_loss: 1.9508 - val_accuracy: 0.3172\n",
            "Epoch 44/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.5469 - accuracy: 0.4253 - val_loss: 1.9877 - val_accuracy: 0.3448\n",
            "Epoch 45/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.5184 - accuracy: 0.4287 - val_loss: 2.0854 - val_accuracy: 0.2897\n",
            "Epoch 46/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.5177 - accuracy: 0.4098 - val_loss: 1.9698 - val_accuracy: 0.2690\n",
            "Epoch 47/200\n",
            "37/37 [==============================] - 2s 60ms/step - loss: 1.5076 - accuracy: 0.4167 - val_loss: 1.9821 - val_accuracy: 0.2345\n",
            "Epoch 48/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.5492 - accuracy: 0.4003 - val_loss: 1.9776 - val_accuracy: 0.2414\n",
            "Epoch 49/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.5439 - accuracy: 0.4184 - val_loss: 2.0018 - val_accuracy: 0.2759\n",
            "Epoch 50/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.4597 - accuracy: 0.4450 - val_loss: 1.9679 - val_accuracy: 0.3241\n",
            "Epoch 51/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.4434 - accuracy: 0.4467 - val_loss: 1.9918 - val_accuracy: 0.3172\n",
            "Epoch 52/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.4653 - accuracy: 0.4373 - val_loss: 2.0636 - val_accuracy: 0.2966\n",
            "Epoch 53/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.4339 - accuracy: 0.4442 - val_loss: 1.9520 - val_accuracy: 0.2966\n",
            "Epoch 54/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.3963 - accuracy: 0.4562 - val_loss: 1.9862 - val_accuracy: 0.3310\n",
            "Epoch 55/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.3773 - accuracy: 0.4682 - val_loss: 1.8918 - val_accuracy: 0.2966\n",
            "Epoch 56/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.4233 - accuracy: 0.4545 - val_loss: 2.0259 - val_accuracy: 0.2828\n",
            "Epoch 57/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 1.3601 - accuracy: 0.4991 - val_loss: 2.0089 - val_accuracy: 0.3379\n",
            "Epoch 58/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.3551 - accuracy: 0.4983 - val_loss: 1.9262 - val_accuracy: 0.3172\n",
            "Epoch 59/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.3725 - accuracy: 0.4931 - val_loss: 2.0793 - val_accuracy: 0.3241\n",
            "Epoch 60/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.3270 - accuracy: 0.4785 - val_loss: 2.0566 - val_accuracy: 0.2966\n",
            "Epoch 61/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.3141 - accuracy: 0.5034 - val_loss: 2.0550 - val_accuracy: 0.3034\n",
            "Epoch 62/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.2976 - accuracy: 0.5275 - val_loss: 2.0223 - val_accuracy: 0.3172\n",
            "Epoch 63/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.2796 - accuracy: 0.5180 - val_loss: 2.2684 - val_accuracy: 0.3517\n",
            "Epoch 64/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 1.2954 - accuracy: 0.5095 - val_loss: 2.0234 - val_accuracy: 0.3517\n",
            "Epoch 65/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.2501 - accuracy: 0.5103 - val_loss: 2.1420 - val_accuracy: 0.3448\n",
            "Epoch 66/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 1.2064 - accuracy: 0.5284 - val_loss: 2.0997 - val_accuracy: 0.3103\n",
            "Epoch 67/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.1910 - accuracy: 0.5524 - val_loss: 2.2202 - val_accuracy: 0.3310\n",
            "Epoch 68/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.1454 - accuracy: 0.5739 - val_loss: 2.2088 - val_accuracy: 0.3241\n",
            "Epoch 69/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.2441 - accuracy: 0.5387 - val_loss: 2.2240 - val_accuracy: 0.3172\n",
            "Epoch 70/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.1771 - accuracy: 0.5421 - val_loss: 2.2828 - val_accuracy: 0.2966\n",
            "Epoch 71/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.1816 - accuracy: 0.5387 - val_loss: 2.1068 - val_accuracy: 0.3448\n",
            "Epoch 72/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.1287 - accuracy: 0.5679 - val_loss: 2.2132 - val_accuracy: 0.2966\n",
            "Epoch 73/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.1378 - accuracy: 0.5756 - val_loss: 2.2121 - val_accuracy: 0.3448\n",
            "Epoch 74/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.1446 - accuracy: 0.5679 - val_loss: 2.3015 - val_accuracy: 0.3379\n",
            "Epoch 75/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.0965 - accuracy: 0.6005 - val_loss: 2.1565 - val_accuracy: 0.3517\n",
            "Epoch 76/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 1.0568 - accuracy: 0.5997 - val_loss: 2.1006 - val_accuracy: 0.3310\n",
            "Epoch 77/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.0853 - accuracy: 0.6074 - val_loss: 2.1919 - val_accuracy: 0.2828\n",
            "Epoch 78/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.0297 - accuracy: 0.6031 - val_loss: 2.3319 - val_accuracy: 0.2897\n",
            "Epoch 79/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.0041 - accuracy: 0.6040 - val_loss: 2.1477 - val_accuracy: 0.3448\n",
            "Epoch 80/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.0416 - accuracy: 0.6117 - val_loss: 2.4462 - val_accuracy: 0.2828\n",
            "Epoch 81/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.9574 - accuracy: 0.6349 - val_loss: 2.4464 - val_accuracy: 0.3034\n",
            "Epoch 82/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.9640 - accuracy: 0.6340 - val_loss: 2.4746 - val_accuracy: 0.2897\n",
            "Epoch 83/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.9721 - accuracy: 0.6392 - val_loss: 2.3675 - val_accuracy: 0.3448\n",
            "Epoch 84/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.8931 - accuracy: 0.6598 - val_loss: 2.5619 - val_accuracy: 0.3103\n",
            "Epoch 85/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.8701 - accuracy: 0.6735 - val_loss: 2.3791 - val_accuracy: 0.3517\n",
            "Epoch 86/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.8899 - accuracy: 0.6830 - val_loss: 2.4710 - val_accuracy: 0.3517\n",
            "Epoch 87/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.9963 - accuracy: 0.6340 - val_loss: 2.6767 - val_accuracy: 0.3034\n",
            "Epoch 88/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.9935 - accuracy: 0.6460 - val_loss: 2.8314 - val_accuracy: 0.3310\n",
            "Epoch 89/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 1.0084 - accuracy: 0.6289 - val_loss: 2.4627 - val_accuracy: 0.3793\n",
            "Epoch 90/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 0.9056 - accuracy: 0.6804 - val_loss: 2.5829 - val_accuracy: 0.3517\n",
            "Epoch 91/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.7964 - accuracy: 0.7062 - val_loss: 2.4687 - val_accuracy: 0.3379\n",
            "Epoch 92/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.7530 - accuracy: 0.7105 - val_loss: 2.8394 - val_accuracy: 0.3103\n",
            "Epoch 93/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.7577 - accuracy: 0.7105 - val_loss: 3.0615 - val_accuracy: 0.2621\n",
            "Epoch 94/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.7942 - accuracy: 0.7122 - val_loss: 3.4435 - val_accuracy: 0.2552\n",
            "Epoch 95/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 0.7819 - accuracy: 0.6942 - val_loss: 2.9381 - val_accuracy: 0.2759\n",
            "Epoch 96/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.7087 - accuracy: 0.7371 - val_loss: 3.0972 - val_accuracy: 0.2690\n",
            "Epoch 97/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.7034 - accuracy: 0.7440 - val_loss: 3.0399 - val_accuracy: 0.2483\n",
            "Epoch 98/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.7976 - accuracy: 0.7122 - val_loss: 2.9575 - val_accuracy: 0.2966\n",
            "Epoch 99/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 0.9295 - accuracy: 0.6847 - val_loss: 2.4593 - val_accuracy: 0.3172\n",
            "Epoch 100/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.7844 - accuracy: 0.7277 - val_loss: 2.8461 - val_accuracy: 0.3034\n",
            "Epoch 101/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 0.6749 - accuracy: 0.7509 - val_loss: 3.1713 - val_accuracy: 0.2966\n",
            "Epoch 102/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 0.6472 - accuracy: 0.7637 - val_loss: 3.0869 - val_accuracy: 0.2414\n",
            "Epoch 103/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.6312 - accuracy: 0.7732 - val_loss: 3.2083 - val_accuracy: 0.2828\n",
            "Epoch 104/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.6579 - accuracy: 0.7509 - val_loss: 3.0668 - val_accuracy: 0.2966\n",
            "Epoch 105/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.6441 - accuracy: 0.7655 - val_loss: 2.9679 - val_accuracy: 0.2897\n",
            "Epoch 106/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.6529 - accuracy: 0.7706 - val_loss: 3.0204 - val_accuracy: 0.3172\n",
            "Epoch 107/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.5488 - accuracy: 0.7921 - val_loss: 3.4450 - val_accuracy: 0.2621\n",
            "Epoch 108/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.5785 - accuracy: 0.7766 - val_loss: 3.3202 - val_accuracy: 0.2414\n",
            "Epoch 109/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 0.8327 - accuracy: 0.7285 - val_loss: 3.7589 - val_accuracy: 0.2828\n",
            "Epoch 110/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 1.0225 - accuracy: 0.6598 - val_loss: 2.4940 - val_accuracy: 0.3724\n",
            "Epoch 111/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.6996 - accuracy: 0.7560 - val_loss: 3.0196 - val_accuracy: 0.3034\n",
            "Epoch 112/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.5388 - accuracy: 0.8170 - val_loss: 2.8598 - val_accuracy: 0.3103\n",
            "Epoch 113/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.5721 - accuracy: 0.8076 - val_loss: 3.0362 - val_accuracy: 0.3172\n",
            "Epoch 114/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.5625 - accuracy: 0.8076 - val_loss: 3.5162 - val_accuracy: 0.2966\n",
            "Epoch 115/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 0.5739 - accuracy: 0.7938 - val_loss: 3.1841 - val_accuracy: 0.3103\n",
            "Epoch 116/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.5389 - accuracy: 0.8162 - val_loss: 3.4924 - val_accuracy: 0.3379\n",
            "Epoch 117/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.4998 - accuracy: 0.8265 - val_loss: 3.7705 - val_accuracy: 0.2828\n",
            "Epoch 118/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.4977 - accuracy: 0.8299 - val_loss: 3.5849 - val_accuracy: 0.2621\n",
            "Epoch 119/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.4675 - accuracy: 0.8282 - val_loss: 4.1515 - val_accuracy: 0.2276\n",
            "Epoch 120/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.4958 - accuracy: 0.8265 - val_loss: 4.0260 - val_accuracy: 0.2621\n",
            "Epoch 121/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.5508 - accuracy: 0.8153 - val_loss: 3.9434 - val_accuracy: 0.3034\n",
            "Epoch 122/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.5068 - accuracy: 0.8256 - val_loss: 3.6668 - val_accuracy: 0.3034\n",
            "Epoch 123/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.4784 - accuracy: 0.8359 - val_loss: 3.6496 - val_accuracy: 0.3103\n",
            "Epoch 124/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.4797 - accuracy: 0.8376 - val_loss: 4.2174 - val_accuracy: 0.2897\n",
            "Epoch 125/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.4404 - accuracy: 0.8497 - val_loss: 3.9143 - val_accuracy: 0.2759\n",
            "Epoch 126/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.4874 - accuracy: 0.8454 - val_loss: 3.9059 - val_accuracy: 0.2897\n",
            "Epoch 127/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 0.5129 - accuracy: 0.8479 - val_loss: 4.4780 - val_accuracy: 0.2690\n",
            "Epoch 128/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 0.3817 - accuracy: 0.8668 - val_loss: 4.0832 - val_accuracy: 0.2552\n",
            "Epoch 129/200\n",
            "37/37 [==============================] - 2s 61ms/step - loss: 0.3907 - accuracy: 0.8651 - val_loss: 4.1656 - val_accuracy: 0.2966\n",
            "Epoch 130/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.3921 - accuracy: 0.8548 - val_loss: 4.1828 - val_accuracy: 0.2759\n",
            "Epoch 131/200\n",
            "37/37 [==============================] - 2s 62ms/step - loss: 0.3659 - accuracy: 0.8823 - val_loss: 4.4212 - val_accuracy: 0.2690\n",
            "Epoch 132/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.4052 - accuracy: 0.8720 - val_loss: 4.3289 - val_accuracy: 0.2828\n",
            "Epoch 133/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.4444 - accuracy: 0.8668 - val_loss: 4.3790 - val_accuracy: 0.3034\n",
            "Epoch 134/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.4863 - accuracy: 0.8376 - val_loss: 3.8247 - val_accuracy: 0.2759\n",
            "Epoch 135/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.4027 - accuracy: 0.8557 - val_loss: 3.9002 - val_accuracy: 0.3172\n",
            "Epoch 136/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.3080 - accuracy: 0.8909 - val_loss: 4.5679 - val_accuracy: 0.2552\n",
            "Epoch 137/200\n",
            "37/37 [==============================] - 2s 67ms/step - loss: 0.2627 - accuracy: 0.9192 - val_loss: 4.7680 - val_accuracy: 0.2828\n",
            "Epoch 138/200\n",
            "37/37 [==============================] - 2s 66ms/step - loss: 0.3240 - accuracy: 0.8875 - val_loss: 5.0731 - val_accuracy: 0.2966\n",
            "Epoch 139/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.3387 - accuracy: 0.8900 - val_loss: 5.1567 - val_accuracy: 0.2414\n",
            "Epoch 140/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.7006 - accuracy: 0.8179 - val_loss: 4.0981 - val_accuracy: 0.2483\n",
            "Epoch 141/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.4751 - accuracy: 0.8454 - val_loss: 4.0109 - val_accuracy: 0.2690\n",
            "Epoch 142/200\n",
            "37/37 [==============================] - 2s 66ms/step - loss: 0.4038 - accuracy: 0.8729 - val_loss: 3.9872 - val_accuracy: 0.2897\n",
            "Epoch 143/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.2749 - accuracy: 0.9141 - val_loss: 4.7193 - val_accuracy: 0.2621\n",
            "Epoch 144/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.3211 - accuracy: 0.9012 - val_loss: 4.2923 - val_accuracy: 0.3172\n",
            "Epoch 145/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.2833 - accuracy: 0.9107 - val_loss: 4.6923 - val_accuracy: 0.3172\n",
            "Epoch 146/200\n",
            "37/37 [==============================] - 2s 66ms/step - loss: 0.3495 - accuracy: 0.8960 - val_loss: 4.6928 - val_accuracy: 0.3379\n",
            "Epoch 147/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.3031 - accuracy: 0.9098 - val_loss: 4.8882 - val_accuracy: 0.2759\n",
            "Epoch 148/200\n",
            "37/37 [==============================] - 2s 66ms/step - loss: 0.2789 - accuracy: 0.9064 - val_loss: 4.9389 - val_accuracy: 0.2828\n",
            "Epoch 149/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.2368 - accuracy: 0.9261 - val_loss: 5.0465 - val_accuracy: 0.2759\n",
            "Epoch 150/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.1896 - accuracy: 0.9407 - val_loss: 5.2238 - val_accuracy: 0.2897\n",
            "Epoch 151/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.3077 - accuracy: 0.9115 - val_loss: 5.3857 - val_accuracy: 0.3103\n",
            "Epoch 152/200\n",
            "37/37 [==============================] - 2s 66ms/step - loss: 0.2996 - accuracy: 0.9115 - val_loss: 5.5040 - val_accuracy: 0.2759\n",
            "Epoch 153/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.1922 - accuracy: 0.9416 - val_loss: 5.7448 - val_accuracy: 0.2621\n",
            "Epoch 154/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.2490 - accuracy: 0.9167 - val_loss: 5.7892 - val_accuracy: 0.2966\n",
            "Epoch 155/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.3079 - accuracy: 0.8952 - val_loss: 5.5197 - val_accuracy: 0.2621\n",
            "Epoch 156/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.7724 - accuracy: 0.8076 - val_loss: 4.6963 - val_accuracy: 0.2897\n",
            "Epoch 157/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.6810 - accuracy: 0.8093 - val_loss: 4.7683 - val_accuracy: 0.2621\n",
            "Epoch 158/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.8447 - accuracy: 0.7328 - val_loss: 3.9799 - val_accuracy: 0.2414\n",
            "Epoch 159/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.5232 - accuracy: 0.8273 - val_loss: 4.0413 - val_accuracy: 0.2828\n",
            "Epoch 160/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.3414 - accuracy: 0.9003 - val_loss: 4.0080 - val_accuracy: 0.3034\n",
            "Epoch 161/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.2759 - accuracy: 0.9124 - val_loss: 4.7994 - val_accuracy: 0.2483\n",
            "Epoch 162/200\n",
            "37/37 [==============================] - 3s 68ms/step - loss: 0.3044 - accuracy: 0.9167 - val_loss: 4.3918 - val_accuracy: 0.3034\n",
            "Epoch 163/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.2136 - accuracy: 0.9433 - val_loss: 4.7606 - val_accuracy: 0.2828\n",
            "Epoch 164/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.1839 - accuracy: 0.9476 - val_loss: 4.9397 - val_accuracy: 0.2897\n",
            "Epoch 165/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.1636 - accuracy: 0.9570 - val_loss: 5.0089 - val_accuracy: 0.2897\n",
            "Epoch 166/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.1454 - accuracy: 0.9553 - val_loss: 5.7129 - val_accuracy: 0.2966\n",
            "Epoch 167/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.1192 - accuracy: 0.9665 - val_loss: 5.6410 - val_accuracy: 0.2966\n",
            "Epoch 168/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.1330 - accuracy: 0.9622 - val_loss: 5.4908 - val_accuracy: 0.2897\n",
            "Epoch 169/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.1349 - accuracy: 0.9527 - val_loss: 5.4938 - val_accuracy: 0.3103\n",
            "Epoch 170/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.3497 - accuracy: 0.9098 - val_loss: 4.6206 - val_accuracy: 0.2966\n",
            "Epoch 171/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.3811 - accuracy: 0.8900 - val_loss: 4.8182 - val_accuracy: 0.2690\n",
            "Epoch 172/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.3211 - accuracy: 0.8995 - val_loss: 5.2820 - val_accuracy: 0.3103\n",
            "Epoch 173/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.2324 - accuracy: 0.9261 - val_loss: 4.7325 - val_accuracy: 0.2759\n",
            "Epoch 174/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.2000 - accuracy: 0.9424 - val_loss: 5.3930 - val_accuracy: 0.2828\n",
            "Epoch 175/200\n",
            "37/37 [==============================] - 2s 67ms/step - loss: 0.1964 - accuracy: 0.9442 - val_loss: 5.6562 - val_accuracy: 0.3034\n",
            "Epoch 176/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.1991 - accuracy: 0.9373 - val_loss: 4.9022 - val_accuracy: 0.3379\n",
            "Epoch 177/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.4805 - accuracy: 0.8780 - val_loss: 5.3202 - val_accuracy: 0.2552\n",
            "Epoch 178/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.4827 - accuracy: 0.8582 - val_loss: 5.0353 - val_accuracy: 0.2552\n",
            "Epoch 179/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.3051 - accuracy: 0.9064 - val_loss: 4.9327 - val_accuracy: 0.3034\n",
            "Epoch 180/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.2032 - accuracy: 0.9442 - val_loss: 4.9856 - val_accuracy: 0.3241\n",
            "Epoch 181/200\n",
            "37/37 [==============================] - 2s 66ms/step - loss: 0.1864 - accuracy: 0.9493 - val_loss: 5.1717 - val_accuracy: 0.3034\n",
            "Epoch 182/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.1825 - accuracy: 0.9476 - val_loss: 5.3186 - val_accuracy: 0.3034\n",
            "Epoch 183/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.2098 - accuracy: 0.9450 - val_loss: 5.2899 - val_accuracy: 0.3241\n",
            "Epoch 184/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.2759 - accuracy: 0.9304 - val_loss: 5.3462 - val_accuracy: 0.3241\n",
            "Epoch 185/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.1561 - accuracy: 0.9545 - val_loss: 5.2601 - val_accuracy: 0.3103\n",
            "Epoch 186/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.1444 - accuracy: 0.9553 - val_loss: 5.7727 - val_accuracy: 0.3034\n",
            "Epoch 187/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.1111 - accuracy: 0.9639 - val_loss: 5.7261 - val_accuracy: 0.3103\n",
            "Epoch 188/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.0986 - accuracy: 0.9682 - val_loss: 5.9862 - val_accuracy: 0.3103\n",
            "Epoch 189/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.1087 - accuracy: 0.9691 - val_loss: 6.4746 - val_accuracy: 0.2897\n",
            "Epoch 190/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.1000 - accuracy: 0.9699 - val_loss: 6.4104 - val_accuracy: 0.2690\n",
            "Epoch 191/200\n",
            "37/37 [==============================] - 2s 64ms/step - loss: 0.0948 - accuracy: 0.9768 - val_loss: 6.5392 - val_accuracy: 0.3034\n",
            "Epoch 192/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.0771 - accuracy: 0.9742 - val_loss: 6.3615 - val_accuracy: 0.2966\n",
            "Epoch 193/200\n",
            "37/37 [==============================] - 2s 67ms/step - loss: 0.1335 - accuracy: 0.9570 - val_loss: 6.7270 - val_accuracy: 0.3241\n",
            "Epoch 194/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.0946 - accuracy: 0.9725 - val_loss: 6.8839 - val_accuracy: 0.3172\n",
            "Epoch 195/200\n",
            "37/37 [==============================] - 2s 65ms/step - loss: 0.1109 - accuracy: 0.9785 - val_loss: 6.8121 - val_accuracy: 0.2966\n",
            "Epoch 196/200\n",
            "37/37 [==============================] - 3s 68ms/step - loss: 0.0891 - accuracy: 0.9734 - val_loss: 6.7670 - val_accuracy: 0.2966\n",
            "Epoch 197/200\n",
            "37/37 [==============================] - 2s 66ms/step - loss: 0.0795 - accuracy: 0.9759 - val_loss: 7.4069 - val_accuracy: 0.2759\n",
            "Epoch 198/200\n",
            "37/37 [==============================] - 2s 66ms/step - loss: 0.1714 - accuracy: 0.9519 - val_loss: 6.5528 - val_accuracy: 0.3034\n",
            "Epoch 199/200\n",
            "37/37 [==============================] - 2s 63ms/step - loss: 0.1598 - accuracy: 0.9493 - val_loss: 7.6503 - val_accuracy: 0.2690\n",
            "Epoch 200/200\n",
            "37/37 [==============================] - 2s 67ms/step - loss: 0.2901 - accuracy: 0.9253 - val_loss: 6.7767 - val_accuracy: 0.3379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Loss plots using LSTM model\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs= range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'ro', label ='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label ='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I7l1-4eOAKUC",
        "outputId": "b430e9ca-7138-4e5c-b8ab-d1671ccc4007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}